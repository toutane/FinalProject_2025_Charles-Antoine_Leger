{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "355e3eb5",
   "metadata": {},
   "source": [
    "# Alternating Least Squares (ALS) Collaborative Filtering Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "926180df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5721cd",
   "metadata": {},
   "source": [
    "## Spark Session Initialization\n",
    "Initializing a Spark session with increased memory allocation to handle large datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "00bf7c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"KuaiRecALS\") \\\n",
    "    .config(\"spark.driver.memory\", \"8g\") \\\n",
    "    .config(\"spark.executor.memory\", \"8g\") \\\n",
    "    .config(\"spark.driver.maxResultSize\", \"2g\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61df6203",
   "metadata": {},
   "source": [
    "# Data Loading and Sampling\n",
    "Loading the user-item interaction data and sampling a fraction to fit into memory for demonstration purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "24b1ee41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>video_id</th>\n",
       "      <th>play_duration</th>\n",
       "      <th>video_duration</th>\n",
       "      <th>time</th>\n",
       "      <th>date</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>watch_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>224263</th>\n",
       "      <td>385</td>\n",
       "      <td>6088</td>\n",
       "      <td>3010</td>\n",
       "      <td>14240</td>\n",
       "      <td>2020-08-08 09:49:55.461</td>\n",
       "      <td>20200808.0</td>\n",
       "      <td>1.596851e+09</td>\n",
       "      <td>0.211376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2682796</th>\n",
       "      <td>4275</td>\n",
       "      <td>570</td>\n",
       "      <td>1543</td>\n",
       "      <td>25310</td>\n",
       "      <td>2020-07-29 20:38:30.483</td>\n",
       "      <td>20200729.0</td>\n",
       "      <td>1.596026e+09</td>\n",
       "      <td>0.060964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32875</th>\n",
       "      <td>55</td>\n",
       "      <td>7281</td>\n",
       "      <td>1276</td>\n",
       "      <td>6667</td>\n",
       "      <td>2020-08-28 07:44:46.355</td>\n",
       "      <td>20200828.0</td>\n",
       "      <td>1.598572e+09</td>\n",
       "      <td>0.191390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262283</th>\n",
       "      <td>477</td>\n",
       "      <td>7093</td>\n",
       "      <td>6709</td>\n",
       "      <td>28929</td>\n",
       "      <td>2020-07-14 19:24:31.309</td>\n",
       "      <td>20200714.0</td>\n",
       "      <td>1.594726e+09</td>\n",
       "      <td>0.231913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3228863</th>\n",
       "      <td>5000</td>\n",
       "      <td>7125</td>\n",
       "      <td>2976</td>\n",
       "      <td>6016</td>\n",
       "      <td>2020-07-18 11:21:36.833</td>\n",
       "      <td>20200718.0</td>\n",
       "      <td>1.595042e+09</td>\n",
       "      <td>0.494681</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id  video_id  play_duration  video_duration  \\\n",
       "224263       385      6088           3010           14240   \n",
       "2682796     4275       570           1543           25310   \n",
       "32875         55      7281           1276            6667   \n",
       "262283       477      7093           6709           28929   \n",
       "3228863     5000      7125           2976            6016   \n",
       "\n",
       "                            time        date     timestamp  watch_ratio  \n",
       "224263   2020-08-08 09:49:55.461  20200808.0  1.596851e+09     0.211376  \n",
       "2682796  2020-07-29 20:38:30.483  20200729.0  1.596026e+09     0.060964  \n",
       "32875    2020-08-28 07:44:46.355  20200828.0  1.598572e+09     0.191390  \n",
       "262283   2020-07-14 19:24:31.309  20200714.0  1.594726e+09     0.231913  \n",
       "3228863  2020-07-18 11:21:36.833  20200718.0  1.595042e+09     0.494681  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactions_raw = pd.read_csv(\"data_final_project/KuaiRec 2.0/data/small_matrix.csv\")\n",
    "\n",
    "# Reduce the size of the DataFrame to fit into memory\n",
    "interactions_raw = interactions_raw.sample(frac=0.1, random_state=42)\n",
    "interactions_raw.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96df14f1",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139b46cf",
   "metadata": {},
   "source": [
    "Creating a binary 'is_like' column to represent positive feedback and normalizing ratings for ALS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae13d18b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>video_id</th>\n",
       "      <th>play_duration</th>\n",
       "      <th>video_duration</th>\n",
       "      <th>time</th>\n",
       "      <th>date</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>watch_ratio</th>\n",
       "      <th>ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>224263</th>\n",
       "      <td>385</td>\n",
       "      <td>6088</td>\n",
       "      <td>3010</td>\n",
       "      <td>14240</td>\n",
       "      <td>2020-08-08 09:49:55.461</td>\n",
       "      <td>20200808.0</td>\n",
       "      <td>1.596851e+09</td>\n",
       "      <td>0.211376</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2682796</th>\n",
       "      <td>4275</td>\n",
       "      <td>570</td>\n",
       "      <td>1543</td>\n",
       "      <td>25310</td>\n",
       "      <td>2020-07-29 20:38:30.483</td>\n",
       "      <td>20200729.0</td>\n",
       "      <td>1.596026e+09</td>\n",
       "      <td>0.060964</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32875</th>\n",
       "      <td>55</td>\n",
       "      <td>7281</td>\n",
       "      <td>1276</td>\n",
       "      <td>6667</td>\n",
       "      <td>2020-08-28 07:44:46.355</td>\n",
       "      <td>20200828.0</td>\n",
       "      <td>1.598572e+09</td>\n",
       "      <td>0.191390</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262283</th>\n",
       "      <td>477</td>\n",
       "      <td>7093</td>\n",
       "      <td>6709</td>\n",
       "      <td>28929</td>\n",
       "      <td>2020-07-14 19:24:31.309</td>\n",
       "      <td>20200714.0</td>\n",
       "      <td>1.594726e+09</td>\n",
       "      <td>0.231913</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3228863</th>\n",
       "      <td>5000</td>\n",
       "      <td>7125</td>\n",
       "      <td>2976</td>\n",
       "      <td>6016</td>\n",
       "      <td>2020-07-18 11:21:36.833</td>\n",
       "      <td>20200718.0</td>\n",
       "      <td>1.595042e+09</td>\n",
       "      <td>0.494681</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id  video_id  play_duration  video_duration  \\\n",
       "224263       385      6088           3010           14240   \n",
       "2682796     4275       570           1543           25310   \n",
       "32875         55      7281           1276            6667   \n",
       "262283       477      7093           6709           28929   \n",
       "3228863     5000      7125           2976            6016   \n",
       "\n",
       "                            time        date     timestamp  watch_ratio  \\\n",
       "224263   2020-08-08 09:49:55.461  20200808.0  1.596851e+09     0.211376   \n",
       "2682796  2020-07-29 20:38:30.483  20200729.0  1.596026e+09     0.060964   \n",
       "32875    2020-08-28 07:44:46.355  20200828.0  1.598572e+09     0.191390   \n",
       "262283   2020-07-14 19:24:31.309  20200714.0  1.594726e+09     0.231913   \n",
       "3228863  2020-07-18 11:21:36.833  20200718.0  1.595042e+09     0.494681   \n",
       "\n",
       "         ratings  \n",
       "224263         0  \n",
       "2682796        0  \n",
       "32875          0  \n",
       "262283         0  \n",
       "3228863        0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactions_df = interactions_raw.copy()\n",
    "interactions_df[\"is_like\"] = interactions_df['watch_ratio'].apply(lambda x: 1 if x >= 2 else 0)\n",
    "interactions_df['ratings'] = interactions_df['watch_ratio'].apply(lambda x: 1 if x >= 2 else 0)\n",
    "interactions_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a48d7e5",
   "metadata": {},
   "source": [
    "### Conversion to Spark DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2245cb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_spark = spark.createDataFrame(interactions_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d38a46e",
   "metadata": {},
   "source": [
    "### Selecting Relevant Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cd87bd30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+-------+\n",
      "|user_id|video_id|ratings|\n",
      "+-------+--------+-------+\n",
      "|    385|    6088|      0|\n",
      "|   4275|     570|      0|\n",
      "|     55|    7281|      0|\n",
      "|    477|    7093|      0|\n",
      "|   5000|    7125|      0|\n",
      "+-------+--------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/17 23:09:45 WARN TaskSetManager: Stage 263 contains a task of very large size (2223 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    }
   ],
   "source": [
    "ratings_spark = interactions_spark.select('user_id', 'video_id', 'ratings')\n",
    "ratings_spark.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e190a98",
   "metadata": {},
   "source": [
    "### Indexing User and Item IDs\n",
    "Encoding user and video IDs as numerical indices, which is required for Spark's ALS implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8b069038",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/17 23:09:45 WARN TaskSetManager: Stage 264 contains a task of very large size (2223 KiB). The maximum recommended task size is 1000 KiB.\n",
      "25/05/17 23:09:45 WARN TaskSetManager: Stage 267 contains a task of very large size (2223 KiB). The maximum recommended task size is 1000 KiB.\n",
      "25/05/17 23:09:45 WARN TaskSetManager: Stage 270 contains a task of very large size (2223 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+-------+--------------+-------------+\n",
      "|user_id|video_id|ratings|video_id_index|user_id_index|\n",
      "+-------+--------+-------+--------------+-------------+\n",
      "|    385|    6088|      0|        1511.0|        549.0|\n",
      "|   4275|     570|      0|        2641.0|        354.0|\n",
      "|     55|    7281|      0|        2204.0|       1298.0|\n",
      "|    477|    7093|      0|        2087.0|        307.0|\n",
      "|   5000|    7125|      0|          53.0|        655.0|\n",
      "+-------+--------+-------+--------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "indexer = [\n",
    "    StringIndexer(inputCol=column, outputCol=column + \"_index\")\n",
    "    for column in list(set(ratings_spark.columns) - set([\"ratings\"]))\n",
    "]\n",
    "\n",
    "pipeline = Pipeline(stages=indexer)\n",
    "transformed = pipeline.fit(ratings_spark).transform(ratings_spark)\n",
    "transformed.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09cb1a7f",
   "metadata": {},
   "source": [
    "### Train-Test Split\n",
    "Splitting the data into training and test sets to evaluate model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "85e0c962",
   "metadata": {},
   "outputs": [],
   "source": [
    "(training, test) = transformed.randomSplit([0.8, 0.2], seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd2dc23",
   "metadata": {},
   "source": [
    "# ALS Model Training\n",
    "Configuring and training the ALS model to learn latent factors for users and items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a4004217",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/17 23:09:45 WARN TaskSetManager: Stage 271 contains a task of very large size (2223 KiB). The maximum recommended task size is 1000 KiB.\n",
      "25/05/17 23:09:45 WARN TaskSetManager: Stage 272 contains a task of very large size (2223 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    }
   ],
   "source": [
    "als = ALS(\n",
    "    maxIter=5,\n",
    "    regParam=0.25,\n",
    "    rank=25,\n",
    "    userCol=\"user_id_index\",\n",
    "    itemCol=\"video_id_index\",\n",
    "    ratingCol=\"ratings\",\n",
    "    coldStartStrategy=\"drop\",\n",
    "    nonnegative=True,\n",
    ")\n",
    "\n",
    "model = als.fit(training)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb2850f",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "Evaluating the ALS model using RMSE on the test set to assess prediction accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4f703445",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/17 23:09:46 WARN TaskSetManager: Stage 305 contains a task of very large size (2223 KiB). The maximum recommended task size is 1000 KiB.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE=0.21494733109519942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/17 23:09:47 WARN TaskSetManager: Stage 344 contains a task of very large size (2223 KiB). The maximum recommended task size is 1000 KiB.\n",
      "[Stage 358:===>            (2 + 8) / 10][Stage 359:>               (0 + 6) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+-------+--------------+-------------+-------------+\n",
      "|user_id|video_id|ratings|video_id_index|user_id_index|   prediction|\n",
      "+-------+--------+-------+--------------+-------------+-------------+\n",
      "|   1015|    8718|      0|        1645.0|        392.0|1.3681786E-10|\n",
      "|   2139|    8718|      0|        1645.0|       1064.0| 8.910314E-11|\n",
      "|   1884|   10364|      0|        1238.0|       1269.0|1.2824435E-11|\n",
      "|   1354|    8718|      0|        1645.0|        860.0|8.5908274E-11|\n",
      "|    896|   10416|      0|        2122.0|        222.0|3.9887837E-12|\n",
      "+-------+--------+-------+--------------+-------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "evaluator = RegressionEvaluator(\n",
    "    metricName=\"rmse\", labelCol=\"ratings\", predictionCol=\"prediction\"\n",
    ")\n",
    "\n",
    "predictions = model.transform(test)\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "\n",
    "print(\"RMSE=\" + str(rmse))\n",
    "predictions.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "03bcbb49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 395:==================================>                  (66 + 14) / 100]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------------+\n",
      "|user_id_index|     recommendations|\n",
      "+-------------+--------------------+\n",
      "|           12|[{2241, 3.3055317...|\n",
      "|           22|[{2241, 9.2186325...|\n",
      "|           26|[{2241, 1.180758E...|\n",
      "|           27|[{2241, 1.9269052...|\n",
      "|           28|[{2241, 2.177901E...|\n",
      "|           31|[{2241, 5.652655E...|\n",
      "|           34|[{2241, 7.935188E...|\n",
      "|           44|[{2241, 4.964044E...|\n",
      "|           47|[{2241, 4.3555692...|\n",
      "|           53|[{2241, 1.9381602...|\n",
      "+-------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "user_recs = model.recommendForAllUsers(20).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbfc4cc2",
   "metadata": {},
   "source": [
    "## Post-processing Recommendations\n",
    "Converting Spark recommendations to Pandas, mapping indices back to original IDs, and organizing recommendations for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4437fc92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/17 23:09:51 WARN TaskSetManager: Stage 440 contains a task of very large size (2223 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      user_id                                    recommendations\n",
      "0          14  [(9178, 5.043813144922638e-10), (5464, 4.58507...\n",
      "1          19  [(600, 2.7589139306449795e-10), (5525, 2.53410...\n",
      "2          21  [(1305, 5.332920216538639e-10), (2130, 4.43843...\n",
      "3          23  [(2130, 7.548934810586161e-10), (7383, 7.70229...\n",
      "4          24  [(154, 7.266417467732822e-10), (600, 8.0075612...\n",
      "...       ...                                                ...\n",
      "1406     7142  [(314, 1.8574650151315097e-10), (7383, 1.95947...\n",
      "1407     7147  [(7383, 3.6516792367713435e-10), (1305, 4.3004...\n",
      "1408     7153  [(4040, 1.7924446649164594e-10), (5525, 1.6438...\n",
      "1409     7159  [(2130, 5.6445453866516e-10), (5525, 5.5618692...\n",
      "1410     7162  [(9178, 1.4693225525164166e-09), (7383, 1.3762...\n",
      "\n",
      "[1411 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/14/crm6wxzx7813ytz60bfsjbhm0000gn/T/ipykernel_16343/973738124.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new[\"recommendations\"] = list(zip(new.video_id, new.ratings))\n"
     ]
    }
   ],
   "source": [
    "recs = model.recommendForAllUsers(10).toPandas()\n",
    "df_recs = (\n",
    "    recs.recommendations.apply(pd.Series)\n",
    "    .merge(recs, right_index=True, left_index=True)\n",
    "    .drop([\"recommendations\"], axis=1)\n",
    "    .melt(id_vars=[\"user_id_index\"], value_name=\"recommendation\")\n",
    "    .drop(\"variable\", axis=1)\n",
    "    .dropna()\n",
    ")\n",
    "\n",
    "df_recs = df_recs.sort_values(\"user_id_index\")\n",
    "df_recs = pd.concat(\n",
    "    [df_recs[\"recommendation\"].apply(pd.Series), df_recs[\"user_id_index\"]], axis=1\n",
    ")\n",
    "\n",
    "df_recs.columns = [\"product_id_index\", \"ratings\", \"reviewer_id\"]\n",
    "tmp = transformed.select(\n",
    "    transformed[\"user_id\"],\n",
    "    transformed[\"user_id_index\"],\n",
    "    transformed[\"video_id\"],\n",
    "    transformed[\"video_id_index\"],\n",
    ")\n",
    "tmp = tmp.toPandas()\n",
    "\n",
    "dict1 = dict(zip(tmp[\"user_id_index\"], tmp[\"user_id\"]))\n",
    "dict2 = dict(zip(tmp[\"video_id_index\"], tmp[\"video_id\"]))\n",
    "\n",
    "df_recs_copy = df_recs.copy()\n",
    "df_recs_copy.loc[:, \"user_id\"] = df_recs[\"reviewer_id\"].map(dict1)\n",
    "df_recs_copy.loc[:, \"video_id\"] = df_recs[\"product_id_index\"].map(dict2)\n",
    "df_recs_copy = df_recs_copy.sort_values(\"user_id\")\n",
    "df_recs_copy.reset_index(drop=True, inplace=True)\n",
    "\n",
    "new = df_recs_copy[[\"user_id\", \"video_id\", \"ratings\"]]\n",
    "new[\"recommendations\"] = list(zip(new.video_id, new.ratings))\n",
    "\n",
    "res = new[[\"user_id\", \"recommendations\"]]\n",
    "res_new = res[\"recommendations\"].groupby([res.user_id]).apply(list).reset_index()\n",
    "\n",
    "print(res_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a2c380",
   "metadata": {},
   "source": [
    "### Evaluation for a Specific User\n",
    "Evaluating the recommendations for a specific user by comparing recommended videos to those the user actually liked, and calculating precision and recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a3bc8412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9178, 5464, 1305, 7383, 314, 5525, 600, 154, 4040, 2130]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'is_like'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/rema-project/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3804\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3805\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3806\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'is_like'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m video_ids = [video_id \u001b[38;5;28;01mfor\u001b[39;00m video_id, _ \u001b[38;5;129;01min\u001b[39;00m user_recommendations]\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(video_ids)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m truth = \u001b[38;5;28mset\u001b[39m(interactions_df[(interactions_df[\u001b[33m\"\u001b[39m\u001b[33muser_id\u001b[39m\u001b[33m\"\u001b[39m] == user_id) & (\u001b[43minteractions_df\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mis_like\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m == \u001b[32m1\u001b[39m)][\u001b[33m\"\u001b[39m\u001b[33mvideo_id\u001b[39m\u001b[33m\"\u001b[39m].values)\n\u001b[32m      7\u001b[39m precision = \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m(video_ids) & \u001b[38;5;28mset\u001b[39m(truth)) / \u001b[38;5;28mlen\u001b[39m(video_ids) \u001b[38;5;28;01mif\u001b[39;00m video_ids \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0\u001b[39m\n\u001b[32m      8\u001b[39m recall = \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m(video_ids) & \u001b[38;5;28mset\u001b[39m(truth)) / \u001b[38;5;28mlen\u001b[39m(truth) \u001b[38;5;28;01mif\u001b[39;00m truth \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/rema-project/lib/python3.12/site-packages/pandas/core/frame.py:4102\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4101\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4102\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4104\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/rema-project/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3807\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3808\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3809\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3810\u001b[39m     ):\n\u001b[32m   3811\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3814\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3815\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3816\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3817\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'is_like'"
     ]
    }
   ],
   "source": [
    "user_id = 14\n",
    "user_recommendations = res_new[res_new[\"user_id\"] == user_id][\"recommendations\"].values[0]\n",
    "video_ids = [video_id for video_id, _ in user_recommendations]\n",
    "print(video_ids)\n",
    "truth = set(interactions_df[(interactions_df[\"user_id\"] == user_id) & (interactions_df[\"is_like\"] == 1)][\"video_id\"].values)\n",
    "\n",
    "precision = len(set(video_ids) & set(truth)) / len(video_ids) if video_ids else 0\n",
    "recall = len(set(video_ids) & set(truth)) / len(truth) if truth else 0\n",
    "print(f\"Precision: {precision}, Recall: {recall}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rema-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
