{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb5d50d5",
   "metadata": {},
   "source": [
    "# Learning-to-Rank Content-Based Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df7dbadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from xgboost import XGBRanker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89061a58",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243cafcd",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cf4f417",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Check if KuaiRec.zip already exists\n",
    "if [ ! -f KuaiRec.zip ]; then\n",
    "    wget --no-check-certificate 'https://drive.usercontent.google.com/download?id=1qe5hOSBxzIuxBb1G_Ih5X-O65QElollE&export=download&confirm=t&uuid=b2002093-cc6e-4bd5-be47-9603f0b33470\n",
    "' -O KuaiRec.zip\n",
    "    unzip KuaiRec.zip -d data_final_project\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfbbabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_raw = pd.read_csv(\"data_final_project/KuaiRec 2.0/data/small_matrix.csv\")\n",
    "user_features = pd.read_csv(\"data_final_project/KuaiRec 2.0/data/user_features.csv\")\n",
    "item_daily_features = pd.read_csv(\"data_final_project/KuaiRec 2.0/data/item_daily_features.csv\")\n",
    "item_categories = pd.read_csv(\"data_final_project/KuaiRec 2.0/data/item_categories.csv\")\n",
    "big_matrix = pd.read_csv(\"data_final_project/KuaiRec 2.0/data/big_matrix.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77e0e7b",
   "metadata": {},
   "source": [
    "### Creation of the \"Combined\" Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2047a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions = interactions_raw.copy()\n",
    "interactions[\"is_like\"] = interactions[\"watch_ratio\"].apply(lambda x: 1 if x >= 2 else 0)\n",
    "interactions = interactions.drop(columns=[\"play_duration\", \"video_duration\", \"time\", \"date\", \"timestamp\"])\n",
    "\n",
    "interactions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71bb2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_daily_features_raw = pd.read_csv(\"data_final_project/KuaiRec 2.0/data/item_daily_features.csv\")\n",
    "\n",
    "cols = set(item_daily_features_raw.columns)\n",
    "cols_to_keep = set([\"video_id\", \"author_id\", \"music_id\", \"comment_cnt\", \"like_cnt\", \"share_cnt\", \"show_cnt\"])\n",
    "cols_to_drop = cols - set(cols_to_keep)\n",
    "\n",
    "video_features = item_daily_features_raw.copy()\n",
    "video_features = video_features.drop(columns=cols_to_drop)\n",
    "\n",
    "video_features = video_features.groupby(by=[\"video_id\"]).first().reset_index()\n",
    "\n",
    "video_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7011d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_categories_raw = pd.read_csv(\"data_final_project/KuaiRec 2.0/data/item_categories.csv\")\n",
    "video_tags = item_categories_raw.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d7bdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "videos = video_features.merge(video_tags, on=\"video_id\", how=\"left\")\n",
    "videos = videos.rename(columns={\"author_id\": \"creator_id\", \"feat\": \"tag_list\"})\n",
    "\n",
    "videos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194f963f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine tag_list, music_id, creator_id as features\n",
    "videos['tag_list'] = videos['tag_list'].fillna('').apply(lambda x: x.replace(',', ' '))\n",
    "videos['tag_list'] = videos['tag_list'].apply(lambda x: x.replace('[', ''))\n",
    "videos['tag_list'] = videos['tag_list'].apply(lambda x: x.replace(']', ''))\n",
    "#videos['combined'] = videos['music_id'].astype(str) + ' ' + videos['creator_id'].astype(str) + ' ' + videos['tag_list'] + ' ' + videos[\"comment_cnt\"].astype(str) + ' ' + videos[\"share_cnt\"].astype(str) + ' ' + videos[\"like_cnt\"].astype(str)\n",
    "videos['combined'] = ''\n",
    "for col in cols_to_keep - {'video_id', 'author_id', 'feat'}:\n",
    "    videos['combined'] =  videos['combined'] + ' ' + videos[col].astype(str)\n",
    "videos['combined'] = videos['combined'] + videos['creator_id'].astype(str) + ' ' + videos['tag_list']\n",
    "\n",
    "#videos['combined'] = videos['tag_list']\n",
    "\n",
    "# Vectorize using TF-IDF\n",
    "tfidf = TfidfVectorizer(max_features=100)\n",
    "video_features = tfidf.fit_transform(videos['combined'])\n",
    "\n",
    "# Build mapping from video_id to vector\n",
    "from scipy.sparse import csr_matrix\n",
    "import numpy as np\n",
    "\n",
    "video_id_to_idx = {vid: i for i, vid in enumerate(videos['video_id'])}\n",
    "video_feature_dict = {\n",
    "    vid: video_features[video_id_to_idx[vid]] for vid in videos['video_id']\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3dd2db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "videos.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96cb36d9",
   "metadata": {},
   "source": [
    "## Prepare LTR Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe32571a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# For this example, use binary label: is_like\n",
    "interactions = interactions[interactions['video_id'].isin(video_id_to_idx)]\n",
    "interactions = interactions[['user_id', 'video_id', 'is_like']]\n",
    "\n",
    "# Generate (user, video) features\n",
    "user_video_pairs = []\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for user_id, user_df in tqdm(interactions.groupby('user_id'), desc=\"Building features\"):\n",
    "    for _, row in user_df.iterrows():\n",
    "        video_id = row['video_id']\n",
    "        if video_id in video_feature_dict:\n",
    "            X.append(video_feature_dict[video_id].toarray()[0])  # convert from sparse to dense\n",
    "            y.append(row['is_like'])  # label: 1 if liked, else 0\n",
    "            user_video_pairs.append(user_id)\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99094562",
   "metadata": {},
   "source": [
    "## Group Structure for Learning-to-Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bdd82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_counts = Counter(user_video_pairs)\n",
    "group = [user_counts[u] for u in sorted(user_counts.keys(), key=lambda x: user_video_pairs.index(x))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30de0fa",
   "metadata": {},
   "source": [
    "# Train XGBoost Ranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b39cda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ltr_model = XGBRanker(\n",
    "    objective='rank:ndcg',\n",
    "    eval_metric='ndcg',\n",
    "    booster='gbtree',\n",
    "    eta=0.1,\n",
    "    max_depth=5,\n",
    "    n_estimators=100,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "ltr_model.fit(X, y, group=group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd5961a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_for_user(user_id, candidate_video_ids, top_k=10):\n",
    "    features = []\n",
    "    vids = []\n",
    "\n",
    "    for vid in candidate_video_ids:\n",
    "        if vid in video_feature_dict:\n",
    "            features.append(video_feature_dict[vid].toarray()[0])\n",
    "            vids.append(vid)\n",
    "\n",
    "    preds = ltr_model.predict(np.array(features))\n",
    "    top_indices = np.argsort(preds)[-top_k:][::-1]\n",
    "    return [vids[i] for i in top_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113308b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_topk_metrics(y_true, top_k_preds, k=5):\n",
    "    top_k = top_k_preds[:k]\n",
    "    relevant = set(y_true)\n",
    "    hits = [1 if item in relevant else 0 for item in top_k]\n",
    "\n",
    "    precision = sum(hits) / k\n",
    "    recall = sum(hits) / len(relevant) if relevant else 0.0\n",
    "    dcg = sum(hit / np.log2(i + 2) for i, hit in enumerate(hits))\n",
    "    ideal_hits = [1] * min(len(relevant), k)\n",
    "    idcg = sum(1 / np.log2(i + 2) for i in range(len(ideal_hits)))\n",
    "    ndcg = dcg / idcg if idcg != 0 else 0.0\n",
    "\n",
    "    # MAP@k: mean average precision\n",
    "    ap_sum = 0.0\n",
    "    hit_count = 0\n",
    "    for i, hit in enumerate(hits):\n",
    "        if hit:\n",
    "            hit_count += 1\n",
    "            ap_sum += hit_count / (i + 1)\n",
    "    map_k = ap_sum / min(len(relevant), k) if relevant else 0.0\n",
    "\n",
    "    print(f\"Precision@{k}: {precision}\")\n",
    "    print(f\"Recall@{k}: {recall}\")\n",
    "    print(f\"NDCG@{k}: {ndcg}\")\n",
    "    print(f\"MAP@{k}: {map_k}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9867eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Candidate videos = all videos not yet seen by this user\n",
    "seen_videos = interactions[interactions['user_id'] == user_id]['video_id'].tolist()\n",
    "print(len(seen_videos), \"videos seen by user\", user_id)\n",
    "#print(\"videos liked in seen videos\", len(interactions[interactions['user_id'] == user_id][interactions['is_like'] == 1]['video_id'].tolist()))\n",
    "\n",
    "#candidate_videos = big_matrix[big_matrix['user_id'] == user_id]['video_id'].tolist()\n",
    "#print(len(candidate_videos), \"candidate videos for user\", user_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53afba89",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10\n",
    "user_id = list(user_counts.keys())[0]\n",
    "\n",
    "#top_recommendations = recommend_for_user(user_id, seen_videos, k)\n",
    "top_recommendations = [9178, 5464, 1305, 7383, 314, 5525, 600, 154, 4040, 2130]\n",
    "print(f\"Top Recommendations for user {user_id}:\", top_recommendations)\n",
    "\n",
    "y_true = interactions[(interactions['user_id'] == user_id) & (interactions[\"is_like\"] == 1)][\"video_id\"].tolist()\n",
    "evaluate_topk_metrics(y_true, top_recommendations, k)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rema-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
